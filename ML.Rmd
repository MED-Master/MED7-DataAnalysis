---
title: "ML"
author: "HZ"
date: "08/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
library(ggplot2)
library(tidyverse)
library(tidymodels)
library(skimr)
library(stringr)
library(corrplot)
library(RColorBrewer)
library("PerformanceAnalytics")
library("Hmisc")
library(Rmisc)
library(lubridate)
library(ggbeeswarm)
library(GGally)
library(effsize)
library(magrittr)
library(dplyr)
library(reticulate)
library(TTR)
library(corrplot)
library(Hmisc)
library(caret)
library(data.table)
library(viridis)
library(hrbrthemes)
library(psycho)
library("devtools")
install_github("tmalsburg/saccades/saccades", dependencies=TRUE, force=TRUE)
library(saccades)
```

```{python Loading packages, include=FALSE}
import numpy as np
import pandas as pd
import pandas as pd
pd.options.mode.chained_assignment = None 
import matplotlib.pyplot as plt
from scipy import stats as sc
import sklearn as sk
import sklearn.preprocessing as pr
import sklearn.decomposition as decomp
import biosppy
import matplotlib
import nolds
import pypi
import hrvanalysis as hrv
```

```{r load in data, include=FALSE}
data <- read.csv("processed_data.csv")
```

```{python standardization, include=FALSE}
py_data = r.data

py_data1 = py_data.drop(['file_path', 'Timestamp', 'condition'], axis=1)

scaler = pr.StandardScaler()
scaled = scaler.fit(py_data1)
scaled = pd.DataFrame(scaler.transform(py_data1), columns = py_data1.columns)

scaled["file_path"] = py_data["file_path"]
scaled["Timestamp"] = py_data["Timestamp"]
scaled["condition"] = py_data["condition"]


scaler = pr.MinMaxScaler()
normalised = scaler.fit(py_data1)
normalised = pd.DataFrame(scaler.transform(py_data1), columns = py_data1.columns)

normalised["file_path"] = py_data["file_path"]
normalised["Timestamp"] = py_data["Timestamp"]
normalised["condition"] = py_data["condition"]
```

```{r save data into r, include=FALSE}
raw_data <- py$py_data 
scaled_data <- py$scaled
normalised_data <- py$normalised

raw_data_VE <- raw_data %>% filter(condition == "VE")
raw_data_NOVE <- raw_data %>% filter(condition == "No VE")
raw_data_nohrv <- raw_data[, 19:ncol(raw_data)]

scaled_data_nohrv <- scaled_data[, 19:ncol(scaled_data)] 
scaled_data_VE <- data.frame(scaled_data) %>% dplyr::filter(condition == "VE") 
scaled_data_NOVE <- data.frame(scaled_data) %>%  dplyr::filter(condition == "No VE")

normalised_data_nohrv <- normalised_data[, 19:ncol(normalised_data)] 
normalised_data_VE <- data.frame(normalised_data) %>%  dplyr::filter(condition == "VE") 
normalised_data_NOVE <- data.frame(normalised_data) %>%  dplyr::filter(condition == "No VE")
```

```{python PCA on RAW data}
def pcaanlysis(df):
  df = df.set_index("Timestamp")
  df = df.drop(["file_path", "condition"], axis=1)
  
  pca = decomp.PCA()
  df_pca = pca.fit(df)
  
  #plt.clf()
  #plot = plt.plot(np.cumsum(pca.explained_variance_ratio_))
  #plt.xlabel('number of components')
  #plt.ylabel('cumulative explained variance');
  #plt.show()
  
  pca = decomp.PCA(n_components = 0.99)
  df_pca = pca.fit(df)
  
  n_pcs= pca.n_components_
  most_important = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]
  initial_feature_names = df.columns
  most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]
  
  df_pca = pd.DataFrame(most_important_names)
  df_pca["variance %"] = pca.explained_variance_ratio_*100
  
  return df_pca


py_scaled = pd.DataFrame(r.scaled_data)
print(pcaanlysis(py_scaled))
py_scaled_nohrv = pd.DataFrame(r.scaled_data_nohrv)
print(pcaanlysis(py_scaled_nohrv))

py_norm = pd.DataFrame(r.normalised_data)
print(pcaanlysis(py_norm))
py_norm_nohrv = pd.DataFrame(r.normalised_data_nohrv)
test = pd.DataFrame(pcaanlysis(py_norm_nohrv))
test.style
```

```{python PCA on scaled data without physio measures}
py_scaled_nophys = pd.DataFrame(r.scaled_data_nohrv)

py_scaled_nophys = py_scaled_nophys.set_index("Timestamp")
py_scaled_nophys = py_scaled_nophys.drop(["file_path", "condition"], axis=1)

pca = decomp.PCA()
py_scaled_nophys_PCA = pca.fit(py_scaled_nophys)

plt.clf()
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');
plt.show()


num_components = 8
pca = decomp.PCA(num_components)
py_scaled_nophys_PCA = pca.fit_transform(py_scaled_nophys)

my_physfree_pca = pd.DataFrame(pca.components_, columns =py_scaled_nophys.columns)

n_pcs = pca.n_components_
imp = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]

initial_feature_names = py_scaled_nophys.columns

most_important_names = [initial_feature_names[imp[i]] for i in range(n_pcs)]

most_important_names
```

```{python PCA on raw data seperated by condition}
py_raw_ve = pd.DataFrame(r.raw_data_VE)
py_raw_ve = py_raw_ve.set_index("Timestamp")
py_raw_ve = py_raw_ve.drop(["file_path", "condition"], axis=1)
pca = decomp.PCA()
py_raw_ve_PCA = pca.fit(py_raw_ve)
plt.clf()
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');
plt.show()
num_components = 4
pca = decomp.PCA(num_components)
py_raw_ve_PCA = pca.fit_transform(py_raw_ve)
n_pcs = pca.n_components_
imp = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]
initial_feature_names = py_raw_ve.columns
most_important_names = [initial_feature_names[imp[i]] for i in range(n_pcs)]
most_important_names

py_raw_nove = pd.DataFrame(r.raw_data_NOVE)
py_raw_nove = py_raw_nove.set_index("Timestamp")
py_raw_nove = py_raw_nove.drop(["file_path", "condition"], axis=1)
pca = decomp.PCA()
py_raw_nove_PCA = pca.fit(py_raw_ve)
plt.clf()
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');
plt.show()
num_components = 4
pca = decomp.PCA(num_components)
py_raw_nove_PCA = pca.fit_transform(py_raw_nove)
n_pcs = pca.n_components_
imp = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]
initial_feature_names = py_raw_nove.columns
most_important_names = [initial_feature_names[imp[i]] for i in range(n_pcs)]
most_important_names
```

```{python PCA on scaled data seperated by condition}
py_raw_ve = pd.DataFrame(r.scaled_data_VE)
py_raw_ve = py_raw_ve.set_index("Timestamp")
py_raw_ve = py_raw_ve.drop(["file_path", "condition"], axis=1)
pca = decomp.PCA()
py_raw_ve_PCA = pca.fit(py_raw_ve)
plt.clf()
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');
plt.show()
num_components = 20
pca = decomp.PCA(num_components)
py_raw_ve_PCA = pca.fit_transform(py_raw_ve)
n_pcs = pca.n_components_
imp = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]
initial_feature_names = py_raw_ve.columns
most_important_names = [initial_feature_names[imp[i]] for i in range(n_pcs)]
most_important_names

py_raw_nove = pd.DataFrame(r.scaled_data_NOVE)
py_raw_nove = py_raw_nove.set_index("Timestamp")
py_raw_nove = py_raw_nove.drop(["file_path", "condition"], axis=1)
pca = decomp.PCA()
py_raw_nove_PCA = pca.fit(py_raw_ve)
plt.clf()
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');
plt.show()
num_components = 20
pca = decomp.PCA(num_components)
py_raw_nove_PCA = pca.fit_transform(py_raw_nove)
n_pcs = pca.n_components_
imp = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]
initial_feature_names = py_raw_nove.columns
most_important_names = [initial_feature_names[imp[i]] for i in range(n_pcs)]
most_important_names
```